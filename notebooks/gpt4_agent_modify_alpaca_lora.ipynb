{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacksonkarel/selfmodifai/blob/main/notebooks/gpt4_agent_modify_alpaca_lora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR_n3zgZIITk"
      },
      "outputs": [],
      "source": [
        "!pip install openai transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YO_QtbfFr4o"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plRBVokoEtkf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "\n",
        "keys = json.load(open('keys.json'))\n",
        "openai.api_key = keys['openai']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GIT_EMAIL\"] = keys[\"git_email\"]\n",
        "os.environ[\"GIT_USERNAME\"] = keys[\"git_username\"]"
      ],
      "metadata": {
        "id": "C3Y86UhYXSCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!rm -rf /root/.ssh\n",
        "\n",
        "!mkdir /root/.ssh\n",
        "\n",
        "!tar xvzf ssh.tar.gz\n",
        "\n",
        "!cp ssh-colab/* /root/.ssh && rm -rf ssh-colab && rm -rf ssh.tar.gz\n",
        "!chmod 700 .shh\n",
        "\n",
        "!touch /root/.ssh/known_hosts\n",
        "!ssh-keyscan github.com >> /root/.ssh/known_hosts\n",
        "!chmod 644 /root/.ssh/known_hosts\n",
        "\n",
        "!git config --global user.email GIT_EMAIL\n",
        "!git config --global user.name GIT_USERNAME\n",
        "!git clone git@github.com:jacksonkarel/selfmodifai-alpaca-lora.git\n",
        "os.chdir(\"selfmodifai-alpaca-lora\")"
      ],
      "metadata": {
        "id": "AWY-kZDGvGX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "access_token = keys[\"github_access_token\"]\n",
        "\n",
        "!git config --global user.email GIT_EMAIL\n",
        "!git config --global user.name GIT_USERNAME\n",
        "\n",
        "os.system(f\"git clone https://{access_token}@github.com/jacksonkarel/selfmodifai-alpaca-lora.git\")\n",
        "os.chdir(\"selfmodifai-alpaca-lora\")"
      ],
      "metadata": {
        "id": "ntGyYoah42pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('messages.json') as json_file:\n",
        "    messages = json.load(json_file)\n",
        "\n",
        "messages.pop()\n",
        "\n",
        "with open('messages.json', 'w') as outfile:\n",
        "    json.dump(messages, outfile)"
      ],
      "metadata": {
        "id": "sQaqZ11EjgV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git restore messages.json"
      ],
      "metadata": {
        "id": "r3ZE2fitHSyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm messages.json"
      ],
      "metadata": {
        "id": "q6qMNh7cpZyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLVzeKezF2z2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "from transformers import pipeline\n",
        "from openai.error import InvalidRequestError\n",
        "\n",
        "def update_messages(content, role, messages):\n",
        "    new_message = {\"role\": role, \"content\": content}\n",
        "    messages.append(new_message)\n",
        "    with open('messages.json', 'w') as outfile:\n",
        "        json.dump(messages, outfile)\n",
        "    \n",
        "    print(f\"Step: {content}\")\n",
        "    return messages\n",
        "\n",
        "def handle_too_long_context(messages):\n",
        "    print(\"too long context\")\n",
        "    messages = messages[:-1]\n",
        "    full_context = \"Condense the information from the following past conversation between us. Keep all of the information that is relevant to the task at hand and remove all that is not:\\n\"\n",
        "    for message in messages[1:]:\n",
        "        role = message[\"role\"]\n",
        "        content = message[\"content\"]\n",
        "\n",
        "        full_context += (f\"{role}: {content}\\n\\n\")\n",
        "    \n",
        "    print(full_context)\n",
        "    system_turn = {'role': 'system', 'content': 'You are part of an agent that is modifying the code of the model Alpaca-LoRA. The agent is in the Alpaca-LoRA directory. When you write code, that code will be executed and the output will be sent back to you.'}\n",
        "    \n",
        "    less_messages = [system_turn, {'role': 'user', 'content': full_context}]\n",
        "    \n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=less_messages\n",
        "                )\n",
        "        less_messages = [system_turn, {'role': 'assistant', 'content': response[\"choices\"][0][\"message\"][\"content\"]}]\n",
        "\n",
        "    except InvalidRequestError as e:\n",
        "            # Check if the error message matches the context length issue\n",
        "            if \"maximum context length\" in str(e):\n",
        "                 response, less_messages = handle_too_long_context(messages)\n",
        "\n",
        "            else:\n",
        "                # Re-raise the exception if it's not what we're looking for\n",
        "                raise e\n",
        "    \n",
        "    return response, less_messages\n",
        "    \n",
        "def gpt4_agent():\n",
        "    with open('messages.json') as json_file:\n",
        "        messages = json.load(json_file)\n",
        "\n",
        "    while True:\n",
        "        \n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=messages\n",
        "            )\n",
        "        except InvalidRequestError as e:\n",
        "            # Check if the error message matches the context length issue\n",
        "            if \"maximum context length\" in str(e):\n",
        "                response, messages = handle_too_long_context(messages)\n",
        "                \n",
        "                with open('messages.json', 'w') as outfile:\n",
        "                    json.dump(messages, outfile)\n",
        "\n",
        "            else:\n",
        "                # Re-raise the exception if it's not what we're looking for\n",
        "                raise e\n",
        "\n",
        "        response_content = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "        \n",
        "        messages = update_messages(response_content, \"assistant\", messages)\n",
        "        \n",
        "        # Define the regular expression pattern\n",
        "        pattern = r'```bash\\n(.*?)\\n```'\n",
        "\n",
        "        matches = re.findall(pattern, response_content, re.DOTALL)\n",
        "\n",
        "        python_content = re.search(r'```python\\n(.*?)\\n```', response_content)\n",
        "\n",
        "        python_prompt = \"Write bash commands to implement those changes in the Python files.\"\n",
        "\n",
        "        bash_response = \"Create bash commands that implement those changes. Give me them one by one.\"\n",
        "        if matches:\n",
        "            content = \"\"\n",
        "        # matches is now a list of all bash commands in the string\n",
        "            for bash_command in matches:\n",
        "                content += f\"{bash_command}:\\n\"\n",
        "                stream = os.popen(bash_command)\n",
        "                \n",
        "                content += stream.read()\n",
        "            \n",
        "            \n",
        "            if python_content:\n",
        "                content = python_prompt\n",
        "\n",
        "            elif not content:\n",
        "                content = \"Ok, did that\"\n",
        "        \n",
        "        elif python_content:\n",
        "            content = python_prompt\n",
        "\n",
        "        elif \"?\" not in response_content:\n",
        "            content = bash_response\n",
        "\n",
        "        else:\n",
        "            classifier = pipeline(\"zero-shot-classification\")\n",
        "            labels = [\"suggestion for what to do next\", \"question\"]\n",
        "            results = classifier(sequences=response_content, candidate_labels=labels, hypothesis_template=\"This text is a {}\") \n",
        "\n",
        "            if results[\"labels\"][0] == \"suggestion for what to do next\":\n",
        "                content = bash_response\n",
        "            \n",
        "            else:\n",
        "                content = \"My goal is to improve the model architecture of Alpaca-LoRA to make it a more powerful language model. Find the answer to that question in that context. If you can't, try another step in improving the language model.\"\n",
        "            \n",
        "        \n",
        "        messages = update_messages(content, \"user\", messages)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt4_agent()"
      ],
      "metadata": {
        "id": "PDMCx-8JTmCa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaiGUReIgq/Z+IPCP2iXh1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}